# ğŸ—ï¸ System Architecture - Earthquake Alert System

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EARTHQUAKE ALERT SYSTEM                       â”‚
â”‚                      (Localhost Version)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   DATA SOURCE    â”‚
                    â”‚                  â”‚
                    â”‚  earthquake_     â”‚
                    â”‚  data.csv        â”‚
                    â”‚  (30 records)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â”‚ Read CSV
                             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         PYSPARK BATCH PROCESSOR            â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Data Loading & Validation       â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Data Cleaning & Transformation  â”‚     â”‚
        â”‚  â”‚  - Remove nulls                  â”‚     â”‚
        â”‚  â”‚  - Extract timestamp features    â”‚     â”‚
        â”‚  â”‚  - Add severity levels           â”‚     â”‚
        â”‚  â”‚  - Add hazard classifications    â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Feature Engineering             â”‚     â”‚
        â”‚  â”‚  - StringIndexer (region)        â”‚     â”‚
        â”‚  â”‚  - VectorAssembler (features)    â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  ML Model Training               â”‚     â”‚
        â”‚  â”‚  - RandomForestClassifier        â”‚     â”‚
        â”‚  â”‚  - 100 trees, maxDepth=10        â”‚     â”‚
        â”‚  â”‚  - 80/20 train/test split        â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Predictions & Evaluation        â”‚     â”‚
        â”‚  â”‚  - Generate hazard predictions   â”‚     â”‚
        â”‚  â”‚  - Calculate probabilities       â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Save Results                    â”‚     â”‚
        â”‚  â”‚  - CSV output                    â”‚     â”‚
        â”‚  â”‚  - Parquet output                â”‚     â”‚
        â”‚  â”‚  - Save trained model            â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                            â”‚
        â”‚  Spark Web UI: http://localhost:4040      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Output Files
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚         OUTPUT & MODEL STORAGE             â”‚
        â”‚                                            â”‚
        â”‚  ğŸ“ output/                                â”‚
        â”‚     â”œâ”€â”€ earthquake_alerts.csv/             â”‚
        â”‚     â””â”€â”€ earthquake_alerts.parquet/         â”‚
        â”‚                                            â”‚
        â”‚  ğŸ“ models/                                â”‚
        â”‚     â””â”€â”€ earthquake_model/                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ Read Data
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          FASTAPI BACKEND                   â”‚
        â”‚       http://localhost:8000                â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Data Loading Module             â”‚     â”‚
        â”‚  â”‚  - Load processed alerts         â”‚     â”‚
        â”‚  â”‚  - Cache in memory               â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  REST API Endpoints              â”‚     â”‚
        â”‚  â”‚                                  â”‚     â”‚
        â”‚  â”‚  GET /alerts                     â”‚     â”‚
        â”‚  â”‚  GET /stats                      â”‚     â”‚
        â”‚  â”‚  GET /predict                    â”‚     â”‚
        â”‚  â”‚  GET /regions                    â”‚     â”‚
        â”‚  â”‚  GET /health                     â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚             â”‚                              â”‚
        â”‚             â–¼                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  Prediction Engine               â”‚     â”‚
        â”‚  â”‚  - Rule-based prediction         â”‚     â”‚
        â”‚  â”‚  - Hazard level calculation      â”‚     â”‚
        â”‚  â”‚  - Risk scoring                  â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                            â”‚
        â”‚  Auto Docs: /docs (Swagger UI)             â”‚
        â”‚             /redoc (ReDoc)                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ HTTP/JSON
                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚        STREAMLIT FRONTEND                  â”‚
        â”‚       http://localhost:8501                â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  ğŸ“Š Dashboard Page               â”‚     â”‚
        â”‚  â”‚  - Key metrics                   â”‚     â”‚
        â”‚  â”‚  - Interactive filters           â”‚     â”‚
        â”‚  â”‚  - Plotly charts (4 types)       â”‚     â”‚
        â”‚  â”‚  - Alerts table                  â”‚     â”‚
        â”‚  â”‚  - CSV download                  â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  ğŸ—ºï¸ Risk Map Page                â”‚     â”‚
        â”‚  â”‚  - Folium interactive map        â”‚     â”‚
        â”‚  â”‚  - GPS markers (color-coded)     â”‚     â”‚
        â”‚  â”‚  - Heatmap overlay               â”‚     â”‚
        â”‚  â”‚  - Tooltips & popups             â”‚     â”‚
        â”‚  â”‚  - Regional statistics           â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  ğŸ”® Prediction Page              â”‚     â”‚
        â”‚  â”‚  - Input form                    â”‚     â”‚
        â”‚  â”‚  - API integration               â”‚     â”‚
        â”‚  â”‚  - Real-time prediction          â”‚     â”‚
        â”‚  â”‚  - Color-coded results           â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â”‚                                            â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
        â”‚  â”‚  âš¡ Spark Web UI Page            â”‚     â”‚
        â”‚  â”‚  - Link to Spark UI              â”‚     â”‚
        â”‚  â”‚  - Usage documentation           â”‚     â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CSV    â”‚â”€â”€â”€â”€â–¶â”‚ PySpark â”‚â”€â”€â”€â”€â–¶â”‚ Output  â”‚â”€â”€â”€â”€â–¶â”‚  FastAPI â”‚
â”‚  Data   â”‚     â”‚  Job    â”‚     â”‚  Files  â”‚     â”‚   API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                     â”‚                                â”‚
                     â”‚                                â”‚
                     â–¼                                â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   ML     â”‚                    â”‚  Streamlit   â”‚
              â”‚  Model   â”‚                    â”‚  Dashboard   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â”‚
                                                     â”‚
                                                     â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚    User      â”‚
                                              â”‚   Browser    â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Component Details

### 1ï¸âƒ£ PySpark Batch Processor

**File:** `spark_job/earthquake_processor.py` (372 lines)

**Purpose:** Process raw earthquake data and train ML model

**Key Functions:**
- `create_spark_session()`: Initialize Spark with Web UI
- `load_data()`: Read CSV data
- `clean_and_transform()`: Data cleaning and feature creation
- `feature_engineering()`: Prepare features for ML
- `train_ml_model()`: Train RandomForestClassifier
- `generate_predictions()`: Predict hazard levels
- `save_results()`: Save processed data

**Technologies:**
- PySpark 3.5.0
- PySpark MLlib
- PySpark SQL

**Inputs:**
- `data/earthquake_data.csv`

**Outputs:**
- `output/earthquake_alerts.csv/`
- `output/earthquake_alerts.parquet/`
- `models/earthquake_model/`

**Port:** 4040 (Spark Web UI)

---

### 2ï¸âƒ£ FastAPI Backend

**File:** `backend/api.py` (334 lines)

**Purpose:** Provide REST API for earthquake data and predictions

**Key Endpoints:**

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API information |
| `/alerts` | GET | Get earthquake alerts (with filters) |
| `/stats` | GET | Summary statistics |
| `/predict` | GET | Hazard prediction |
| `/regions` | GET | List of regions |
| `/health` | GET | Health check |

**Technologies:**
- FastAPI 0.104.1
- Uvicorn (ASGI server)
- Pydantic (data validation)
- Pandas (data processing)

**Port:** 8000

**API Docs:**
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

---

### 3ï¸âƒ£ Streamlit Frontend

**File:** `frontend/app.py` (605 lines)

**Purpose:** Interactive web dashboard for visualization and predictions

**Pages:**

1. **Dashboard** (`dashboard_page()`)
   - Key metrics display
   - Interactive filters
   - 4 Plotly charts
   - Data table
   - CSV download

2. **Risk Map** (`risk_map_page()`)
   - Folium interactive map
   - GPS markers
   - Heatmap overlay
   - Regional statistics

3. **Prediction** (`prediction_page()`)
   - Input form
   - API integration
   - Real-time predictions
   - Color-coded results

4. **Spark Web UI** (`spark_ui_page()`)
   - Link to Spark UI
   - Documentation
   - Usage guide

**Technologies:**
- Streamlit 1.28.2
- Plotly 5.18.0
- Folium 0.15.0
- Pandas
- Requests

**Port:** 8501

---

## ğŸ—„ï¸ Data Model

### Input Data Schema

```
earthquake_data.csv
â”œâ”€â”€ sensor_id: String (e.g., "S01")
â”œâ”€â”€ timestamp: String (e.g., "2024-01-02 05:22:01")
â”œâ”€â”€ latitude: Float (e.g., 34.11)
â”œâ”€â”€ longitude: Float (e.g., -117.22)
â”œâ”€â”€ magnitude: Float (e.g., 5.4)
â”œâ”€â”€ depth: Integer (e.g., 12)
â””â”€â”€ region: String (e.g., "California")
```

### Processed Data Schema

```
earthquake_alerts.csv
â”œâ”€â”€ sensor_id: String
â”œâ”€â”€ timestamp: String
â”œâ”€â”€ latitude: Float
â”œâ”€â”€ longitude: Float
â”œâ”€â”€ magnitude: Float
â”œâ”€â”€ depth: Float
â”œâ”€â”€ region: String
â”œâ”€â”€ severity: String (Low/Medium/High)
â”œâ”€â”€ depth_category: String (Shallow/Intermediate/Deep)
â”œâ”€â”€ hazard_level: Integer (0-3)
â”œâ”€â”€ prediction: Float (predicted hazard level)
â”œâ”€â”€ hazard_probability: Float (0-1)
â””â”€â”€ alert_message: String
```

### ML Model Schema

**Input Features:**
- magnitude: Float
- depth: Float
- region_index: Integer (encoded)
- latitude: Float
- longitude: Float

**Output:**
- prediction: Integer (0-3)
- probability: Vector[4] (probabilities for each class)

**Classes:**
- 0: Low Risk
- 1: Medium Risk
- 2: High Risk
- 3: Critical Risk

---

## ğŸ”’ Security Considerations

### Current Implementation (Localhost)
- No authentication required
- CORS enabled for all origins
- Data stored locally
- No encryption

### Production Recommendations
- Add API authentication (JWT/OAuth)
- Implement rate limiting
- Add input validation
- Use HTTPS
- Restrict CORS origins
- Add database with proper access controls
- Implement logging and monitoring
- Add data encryption

---

## âš¡ Performance Characteristics

### PySpark Job
- **Parallelism:** local[*] (all cores)
- **Shuffle Partitions:** 4
- **Driver Memory:** 2GB
- **Expected Runtime:** 30-60 seconds for 30 records

### API Backend
- **Concurrency:** Async with Uvicorn
- **Response Time:** < 100ms for most endpoints
- **Memory Usage:** ~100-200MB
- **Max Records:** Limited to 100 per request (configurable)

### Frontend
- **Load Time:** 1-3 seconds initial load
- **Chart Rendering:** < 1 second
- **Map Rendering:** 2-5 seconds
- **Memory Usage:** Depends on browser

---

## ğŸ“ˆ Scalability Considerations

### Current Limitations (Localhost)
- Single machine processing
- In-memory data storage
- No distributed computing
- Limited to local file system

### Scaling Options

**Horizontal Scaling:**
- Deploy Spark on cluster (YARN, Kubernetes)
- Use distributed storage (HDFS, S3)
- Add load balancer for API
- Implement caching (Redis)

**Vertical Scaling:**
- Increase driver/executor memory
- Add more CPU cores
- Use faster storage (SSD)

**Data Scaling:**
- Partition data by region/date
- Implement incremental processing
- Add streaming with Spark Structured Streaming
- Use column-oriented storage (Parquet)

---

## ğŸ”„ Workflow Sequence

### Setup Workflow
```
1. User runs: setup.bat
2. Python venv created
3. Dependencies installed
4. Environment ready
```

### Data Processing Workflow
```
1. User runs: run_spark.bat
2. Spark session created (Web UI at :4040)
3. CSV data loaded (30 records)
4. Data cleaned and transformed
5. Features engineered
6. ML model trained (RandomForest)
7. Predictions generated
8. Results saved (CSV + Parquet)
9. Model saved
10. User views Spark Web UI
11. User presses Enter to exit
```

### Runtime Workflow
```
1. User runs: run_api.bat (Terminal 1)
   - API loads processed data
   - Server starts at :8000
   
2. User runs: run_frontend.bat (Terminal 2)
   - Frontend starts at :8501
   - Browser opens automatically
   
3. User interacts with dashboard:
   a. View charts and metrics
   b. Filter data
   c. Download CSV
   
4. User views risk map:
   a. See GPS markers
   b. Click for details
   c. Toggle heatmap
   
5. User makes prediction:
   a. Enter magnitude, depth, region
   b. Click predict
   c. Frontend calls API
   d. API returns prediction
   e. Results displayed
```

---

## ğŸ§ª Testing Architecture

### Unit Testing (Recommended)
- Test individual functions
- Mock Spark context
- Test API endpoints
- Test data transformations

### Integration Testing (Recommended)
- Test Spark â†’ API integration
- Test API â†’ Frontend integration
- Test end-to-end predictions

### Performance Testing (Recommended)
- Load test API endpoints
- Benchmark Spark job with larger datasets
- Test frontend with many markers

---

## ğŸ“¦ Deployment Architecture

### Current: Localhost Development

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Developer Machine        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PySpark :4040         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  FastAPI :8000         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚  Streamlit :8501       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Future: Production Deployment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Load Balancer                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API   â”‚      â”‚  API   â”‚
â”‚ Server â”‚      â”‚ Server â”‚
â”‚   1    â”‚      â”‚   2    â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚              â”‚
     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Database    â”‚
    â”‚ (PostgreSQL)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Spark        â”‚
    â”‚  Cluster      â”‚
    â”‚  (YARN/K8s)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Frontend     â”‚
    â”‚  (CDN)        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ Technology Stack Summary

| Layer | Technology | Version | Purpose |
|-------|-----------|---------|---------|
| **Processing** | PySpark | 3.5.0 | Batch processing |
| **ML** | PySpark MLlib | 3.5.0 | Machine learning |
| **API** | FastAPI | 0.104.1 | REST endpoints |
| **Server** | Uvicorn | 0.24.0 | ASGI server |
| **Frontend** | Streamlit | 1.28.2 | Dashboard |
| **Charts** | Plotly | 5.18.0 | Visualizations |
| **Maps** | Folium | 0.15.0 | Geographic viz |
| **Data** | Pandas | 2.1.3 | Data manipulation |
| **Compute** | NumPy | 1.26.2 | Numerical ops |
| **HTTP** | Requests | 2.31.0 | API calls |

---

## ğŸ“ Configuration Files

| File | Purpose |
|------|---------|
| `requirements.txt` | Python dependencies |
| `setup.bat` | Installation script |
| `run_spark.bat` | Run PySpark job |
| `run_api.bat` | Run API server |
| `run_frontend.bat` | Run dashboard |
| `.gitignore` | Git exclusions |

---

## ğŸ¯ Design Principles

1. **Modularity**: Each component is independent
2. **Separation of Concerns**: Clear separation of layers
3. **Scalability**: Can be extended to cloud
4. **Maintainability**: Well-commented, organized code
5. **User-Friendly**: Simple setup and run scripts
6. **Documentation**: Comprehensive guides
7. **Error Handling**: Graceful error management
8. **Performance**: Optimized for localhost

---

## ğŸš€ Future Enhancements

### Short Term
- Add more ML models (GBT, Neural Networks)
- Implement caching for faster API responses
- Add user authentication
- Add email/SMS alerts

### Medium Term
- Real-time streaming with Spark Structured Streaming
- Database integration (PostgreSQL/MongoDB)
- Advanced analytics (time-series forecasting)
- Mobile app

### Long Term
- Cloud deployment (AWS/Azure/GCP)
- Kubernetes orchestration
- Microservices architecture
- Global CDN for frontend
- Multi-region deployment

---

**ğŸ“Š This architecture is designed to be simple yet scalable, perfect for both learning and production use!**
